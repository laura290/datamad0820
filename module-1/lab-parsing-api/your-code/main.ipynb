{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Promotions\n",
    "\n",
    "In this challenge, you'll develop codes to parse and analyze data returned from another API on Zalando such as [Promos homme (Men's Promotions)\n",
    "](https://www.zalando.fr/promo-homme/) or [Promos femme (Women's Promotions)](https://www.zalando.fr/promo-femme/). The workflow is almost the same as in the guided lesson but you'll work with different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the link\n",
    "\n",
    "Wrote your codes in the cell below to obtain the data from the API endpoint you choose. A recap of the workflow:\n",
    "\n",
    "1. Examine the webpages and choose one that you want to work with.\n",
    "\n",
    "1. Use Google Chrome's DevTools to inspect the XHR network requests. Find out the API endpoint that serves data to the webpage.\n",
    "\n",
    "1. Test the API endpoint in the browser to verify its data.\n",
    "\n",
    "1. Change the page number offset of the API URL to test if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#https://www.zalando.fr/promo-femme/\n",
    "url='www.zalando.fr/api/catalog/articles?categories=promo-femme&limit=84&offset=84&sort=popularity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "In the next cell, use Python to obtain data from the API endpoint you chose in the previous step. Workflow:\n",
    "\n",
    "1. Import libraries.\n",
    "\n",
    "1. Define the initial API endpoint URL.\n",
    "\n",
    "1. Make request to obtain data of the 1st page. Flatten the data and store it in an empty object variable.\n",
    "\n",
    "1. Find out the total page count in the 1st page data.\n",
    "\n",
    "1. Use a FOR loop to make requests for the additional pages from 2 to page count. Append the data of each additional page to the flatterned data object.\n",
    "\n",
    "1. Print and review the data you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 your code here\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "url='https://www.zalando.fr/api/catalog/articles?categories=promo-femme&limit=84&offset=0&sort=popularity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "response = urllib.request.urlopen(url)\n",
    "results = json.load(response)\n",
    "flattened_data = json_normalize(results)\n",
    "flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "flattened_data1\n",
    "lista=flattened_data1.values.tolist()\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 \n",
    "response = urllib.request.urlopen(url)\n",
    "results = json.load(response)\n",
    "total_pages=results['2']['page_count']\n",
    "df=pd.DataFrame()\n",
    "for i in range(total_pages):\n",
    "    k=k*i\n",
    "    url=f'https://www.zalando.fr/api/catalog/articles?categories=promo-femme&limit=84&offset=0&sort=popularity'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    results = json.load(response)\n",
    "    flattened_data = json_normalize(results)\n",
    "    flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "    flattened_data1=flattened_data1.set_index('sku')\n",
    "    df_2= df.append(flattened_data1)\n",
    "    print(f\"getting page {i} of {total_pages}\", end='\\r')\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "total_pages=results['pagina']['page_count']\n",
    "df=pd.DataFrame()\n",
    "for i in range(total_pages):\n",
    "    k=84*i\n",
    "    url=f'https://www.zalando.fr/api/catalog/articles?categories=promo-femme&limit=84&offset=0&sort=popularity'\n",
    "    response = urllib.request.urlopen(url)\n",
    "    results = json.load(response)\n",
    "    flattened_data = json_normalize(results)\n",
    "    flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "    flattened_data1=flattened_data1.set_index('sku')\n",
    "    df = df.append(flattened_data1)\n",
    "    print(f\"getting page {i} of {total_pages}\", end='\\r')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Extract the following information from the data:\n",
    "\n",
    "* The trending brand.\n",
    "\n",
    "* The product(s) with the highest discount.\n",
    "\n",
    "* The sum of discounts of all goods (sum_discounted_prices divided by sum_original_prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adidas Originals'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.brand_name.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price.original']=\n",
    "df['price.promotional']=df['price.promotional'].str.extract('(\\d*,\\d*)')\n",
    "\n",
    "df['price.original'] = [x.replace(',', '.') for x in df['price.original']]\n",
    "df['price.promotional'] = [x.replace(',', '.') for x in df['price.promotional']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discount_amount']=df['price.original'].astype(float)-df['price.promotional'].astype(float)\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disc=df1.groupby(['brand_name']).sum().discount_amount\n",
    "total_disc_2=df.groupby(['brand_name']).sum().price.original\n",
    "total_disc_3 =total_disc/total_disc_2\n",
    "total_disc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
